# Discussion and Future Work {#sec:discussion}

In the previous chapters, I have detailed the main contributions of this thesis: First, the results of an open-ended user testing study that explored the means of collaborative workflows in DH tools. Second, the design and implementation of two P2P systems for collaborative annotation. These contributions emerged from the initial research questions posed in @sec:intro:meta on the aspects of collaborative workflows and the technical feasibility of local-first software in the context of DH infrastructure. Throughout this thesis I have emphasized possible shortcomings on the study framework and the implementations. The following chapters will iterate over all contributions and discuss them in detail.

## Study and Usability Research {#sec:discussion:usability}

The results of the study presented in chapter \ref{sec:study} indicate the validation of initial assumptions on the prospects of real-time synchronization of collaborative applications. While the approach for tracking participants' atomic actions during sessions featured novel insights into their workflows and usability patterns on Recogito, the study design itself has been loose and explorative, which can threaten the reproducibility of its results. In the following, I will address these concerns.

By creating a loose setting, participants could freely explore the means of collaborative annotation on Recogito. Nevertheless, given the open-ended environment, this did not allow to articulate specific hypotheses that we could validate. In that regard, students interacted frequently through chatter and physical interactions, which can distort observations focused purely on online collaboration. Our decision to conduct an explorative study posed a trade-off and required us to provide the participants with a loose environment to explore the sources and annotate "naturally", as opposed to executing highly specified tasks. We also interacted with them during the sessions, although just briefly. Instead of specifying a strict lab setting, we detailed a study framework and our observations. After all, the results presented in @sec:study:results are manyfold and fundamentally shaped the design of the subsequent implementations of chapter \ref{sec:implementation}.

Nevertheless, the method of reconstructing participants' workflows by tracking atomic actions promise further insights into small-scale aspects of digital coolaboration. When reconstructing workflows, researchers are able to not only visualize the exact sequence of actions, but also examine the data acted upon. Considering the concept of _shared feedback_ by @dourish1992, this records would allow to validate collaborative workspaces in terms of how users are able to grasp real-time data. Further work on this method could state key insights, such as the average _age_ of data (i.e., when it has been last modified) in order to estimate the information flow within such a workspace.

Further work could concern a revised study framework with an emphasis on reproducibility and more specific hypothesis validation. By further isolating participants, less noise could be imposed on the resulting data. This could be achieved by establishing strictly-separated remote settings or simply limiting individual interactions within lab. Furthermore, tasks could be expressed more precisely while still considering the aspects of "natural" annotation. Limiting the sample size per session could finally contribute to reducing noise and overall overhead.

In order to gain more sophisticated insights into the usability aspects of real-time collaboration in relation with P2P systems, further work is required. While research on best-practices of data security and usability of data-based systems was already conducted,[^if-library][^simply-secure-kb] there was just few reseach published on the dedicated topic of P2P usability design and patterns. @kleppmann2019 provide a valuable set of practices for realizing local-first applications---such as locally available data, security & privacy, and offline capabilities---yet these provide no practical recommendations for professionals in terms of usability and user interface design. Pattern libraries are popular tools among designers and developers alike for providing accessible and modular best-practices of user interface and interaction design [@borchers2000]. In forthcoming work, a group of researchers from Simply Secure curate a library[^lots] of hands-on patterns and metaphors suited for applications that employ protocols and user interfaces with P2P technology.

[^if-library]: <https://catalogue.projectsbyif.com/>
[^simply-secure-kb]: <https://simplysecure.org/knowledge-base/>
[^lots]: <https://decentpatterns.xyz/>

## Architectural Challenges {#sec:discussion:architecture}

The first implementation of chapter \ref{sec:implementation} leveraged an additional overlay network for connecting clients on the web to peers on the distributed Hyperswarm network. Fundamental issues with the architecture emerged during testing the approach with a small, remote testing group, as I have outlined in @sec:thick:evaluation. I will discuss observations on these issues in the following, which effectively initiated work on the second implementation, Hyperwell.

In the context of distributed collaborative annotation, peers on the network are considered to be peoples' personal devices. These are often running on commodity hardware such as personal computers, tablets, or smartphones. Commodity hardware is commonly limited in terms of computing power compared to professional enterprise servers powering the cloud. Nevertheless, when bridging the web and a P2P network, clients from the web will effectively request data from peers on the P2P network with the expectation of high data availability and low latency. This entails a conflict between the client-server model with distributed systems and will render peers acting as servers on the overlay network. Without additional infrastructures for handling these requests, requests originated from the web will impose a substantial strain on computational resources of peers on the P2P network.

With gateways in Hyperwell, introducing a mandatory intermediate layer between the P2P network and the web helped mitigating possible bottlenecks. Framing this component of the architecture under governance of public entities such as institutions, gateways can be scaled separately from eventual effects on the P2P network. Performance tests on Hyperwell gateways, however, were not conducted during this thesis and are subject to future work, as I will outline in the following.

## Hyperwell, Hyperbetter {#sec:discussion:implementation}

The implementations described in chapter \ref{sec:implementation} are multifaceted and concern autonomy, interoperability, and usability. Hyperwell, which emerged after first attempts at establishing a bridge network between web clients and a P2P network, imposes a separate layer for mediating between both networks. The current ecosystem of Hyperwell includes a gateway server and a prototype annotation environment, with an annotation management application still in development. While Hyperwell proved itself operational during small-scale testing, its compontents currently lack features imposed by the paradigm of local-first applications. Encryption, privacy, and security are fundamental requirements for private collaboration,

On the question on privacy, the P2P network and the web pose different challenges. When accessing resources on a P2P network, the network should be considered an untrusted environment[^dat-privacy-models] as meta information on the requested data is often leaked [@hardenberg2020]. While Hypermerge and Hypercore increasingly adopt encryption models based on public key encryption, the gateway---acting as an intermediary entity---poses challenges for relaying data without encrypting it. With secure HTTP connections using Transport Layer Security (TLS) for encrypting connections between clients and servers, encryption is still terminated on the gateway. In order to ensure end-to-end encryption for increased privacy, further research will need to be conducted on securely extracting pieces from Hypermerge documents and complementing these with the Web Annotation specification.

The gateway server for Hyperwell has been framed as an _institutional_ service, because in the imaginary workflow, institutions would provide services such as archiving or replication to affiliated researchers. The current state of the gatewa software, however, does not pose any limitations on requesting Hypermerge documents, making gateways serve any kind of content that is contained in Hypermerge documents. This is due a lack of managing identities, cryptographic keys, and validating requests, which poses critical issues for running such software in public institutions. A further evaluation of Hyperwell in regard to academic workflows should address these concerns.

Finally, Hyperwell was not exposed to any performance testing. The assumption of independently scalable gateway servers on Hyperwell decreases possible strains on the P2P networks, yet the gateway itself was not evaluated for any bottlenecks or performance issues. Subscriptions can require substantial amounts of processing power for frequently calculating change sets. Hence, further work on Hyperwell should address the gateway's performance when relaying change sets for providing its fundamental capability---bridging P2P networks and the web for real-time collaboration.

[^dat-privacy-models]: <https://blog.datproject.org/2018/01/16/dat-privacy-models/>.

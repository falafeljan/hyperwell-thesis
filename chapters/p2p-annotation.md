# Peer-to-Peer Annotation {#sec:annotation}

Despite its decentralized nature, resources on the web tend to be centralized on a small number of servers. This development intensified even more amidst the rise of Big Data and the continuous commoditization of personal data, threatening data ownership and autonomy on the web. Arguably, academia and particularly the Digital Humanities treat the web differently by embracing LD principles and establishing sustainable and self-organized infrastructures. Furthermore, with the Web Annotation specification issued by the W3C, academic annotation services can be provided by interoperable research environments and digital libraries. Considering annotation in the overall status quo, however, poses the following questions: Does annotation belong to the institutional domain? And if not, where else to store and distribute them with, other than the web?

In the following, I will argue for establishing an architectural separation between personal annotation and the respective sources based on the assumption that annotations are social data. @Sec:annotation:web revisits characteristics of web; after questioning implications of cloud infrastructure in today's internet services, I discuss effects of decentralization in federated networks and P2P systems on digital annotation. P2P systems commonly rely on high-availability infrastructures known as _supernodes_ or _mirrors_ for replication and indexing. @Sec:annotation:infrastructure examines these infrastructures and draws inspiration from public services such as libraries.

In @sec:annotation:ownership, I then define the distinctive terms of _notebooks_ and _public entities_ for establishing a separation between personal data and public services in P2P networks and the web. Subsequently, in the following chapter \ref{sec:implementation}, I discuss proof-of-concept designs and implementations on how such a separation can be realized with P2P technology.

## What's (Not) Wrong with Servers? {#sec:annotation:web}

The web establishes a decentralized network---as reported previously in this thesis---since hypertext systems commonly use a client-server model in order to distribute hypertext documents among a multitude of servers on the network [@berners-lee1989a; @nelson1993]. This architectural decision brings its pros and cons; smaller networks can benefit from this model by being easily scalable and distributing resources predictably, yet large networks of world-wide scale can quickly outgrow their intention of being open, accessible, and collaborative, threatening their heterogeneity:

> _While the Web has the potential to enable full open access to knowledge, the code that powers the Web is not built for that. Instead, the Web uses a centralized data model optimized for use by commercial organizations. In other words, today’s Web values the access and voices of people who are valuable to corporate interests._ [@robinson2018, p. 2]

Businesses became increasingly obsessed with harvesting personal data, which provides them with questionable[^cambridge-analytica][^shadow-profiles] substance for training targeted advertising models and personalization in news feeds [@bucher2012; @robinson2018]. The commodification of personal data by businesses consequently spoon-fed the progression of Big Data and the partitioning of the web into monolithic data silos [@srnicek2017]. Considering the resulting redistribution of resources on the web in its entirety, this inequality led to a fundamental break with the web's decentralized nature:

> _While the Web was originally conceived as a decentralised platform where every organisation and individual can participate, it became increasingly centralised with less than 1% of the servers serving more than 99% of the content._ [@capadisli2017, p. 469]

Arguably, LDP-supporting environments such as Solid and dokieli attempt to mitigate such developments by emphasizing interoperability via server-to-server communication and open standards for data exchange [@mansour2016; @capadisli2017]. Based on fundamental web technologies, decentralized protocols like ActivityPub showed that the web can serve as a topsoil for autonomous and sustainable communities. Furthermore, publicly shared and semantically enriched data repositories can contribute to the digital commons; in Digital Humanities research, such contributions could arise as digital commentary via Web Annotation and digital gazetteers [@simon2017].

In this context, a published collection of annotations on a resource could be considered a critical commentary and thus make for a work of its own [@marshall1997; @marshall1998]. Marginal notes often provide context for sophisticated discussion among readers, rendering such annotations social data. Furthermore, as \citeauthor{marshall1998} notes in her \citeyear{marshall1998} analysis of annotations, there exists a significant difference between annotations that have been made for private purposes and those which were created with public discussion in mind. Similar to a private diary, private annotations are created for private use, and thus personal ownership as well privacy should be protected.

With _local-first software_, \citeauthor{kleppmann2019} introduces a novel type of application based on established concepts with the aim of retaining personal ownership of data [@kleppmann2019]. One technology that is particularly well-suited for use in local-first applications is a CRDT, a data structure that provides strategies for conflict-free merging of changes that emerge from a distributed system with no centralized authority. Under the theoretical assumption of Strong Eventual Consistency (SEC), the retrieval of each separately obtained log of changes will eventually result in the same state across all peers of the system. By furthermore urging for data interoperability and encryption, \citeauthor{kleppmann2019} make local-first applications a promising contender for fixing the web's ownership issues.

Interestingly, the ecosystem of the web is changing. Rooted in the hype for P2P networks from the early 2000s, several protocols for hypermedia data-sharing emerged; namely Dat[^dat-foundation] and IPFS[^ipfs], both of which attempt to provide a foundation for redistributing resources on the web. Yet some of their prospects are not fundamentally new and could actually contribute towards transforming the web to earlier notions of hypertext systems like Xanadu [@voss2019]. Today's browsers increasingly adopt these maturing protocols, with support for Dat and IPFS present in Beaker[^beaker] and Opera[^opera-ipfs], respectively.

However, novel systems which build upon these protocols will need to ensure interoperability with the current web; on the one hand, the web offers a vast amount of knowledge, e.g., publicly accessible PDF documents or semantically-tagged LOD repositories from DH research. On the other hand, the web provides an efficient way for public entities, such as academic institutions and digital libraries, to publish content under their authority. In the following, I attempt to discuss the role of such entities in P2P systems.

[^cambridge-analytica]: <https://www.theguardian.com/technology/2019/jul/12/facebook-fine-ftc-privacy-violations>.
[^shadow-profiles]: <https://www.vox.com/2018/4/20/17254312/facebook-shadow-profiles-data-collection-non-users-mark-zuckerberg>.
[^dat-foundation]: <https://dat.foundation/>.
[^ipfs]: <https://ipfs.io/>.
[^beaker]: <https://beakerbrowser.com/>.
[^opera-ipfs]: The Opera browser for Android recently introduced support for resolving IPFS URLs: <https://blog.ipfs.io/2020-03-30-ipfs-in-opera-for-android/>.

## Public Entities in Peer-to-Peer Systems {#sec:annotation:infrastructure}

_Supernodes, relays, pubs, pods, gateways, pinning, seeding, mirroring:_ Many popular decentralized networks leverage infrastructures that provide resources for sustaining the networks’ operation. Such services are required, since P2P systems operate fundamentally differently from established architectures that use the client-server model. This difference can be explained by how resources are distributed among client and servers on such networks; servers hold a monopoly on the network's resources, while clients request parts of data on demand [@schollmeier2002]. This situation bears several benefits for entities such as businesses and institutions; they are able to govern the singular source of their services’ data by actually _owning_ it. Hence, entities can effectively control and guarantee for aspects like data availability, access control, and data versioning.

In P2P systems, this power is distributed among peers. The distinction of clients and servers becomes blurred as the centralization of governance is diminished: Clients become servers as servers become clients, resulting in a swarm of equal peers that serve and request data at the same time [@schollmeier2002]. Challenges are posed to P2P systems as they are frequented by peoples' personal computers, resulting in commodity hardware or even handheld devices joining the network ephemerally. This threatens data availability on P2P systems, since data vanishes as devices go offline.

However, solutions exist for mitigating volatility or low-performing hardware among peers. In order to establish a stable and reliable overlay network, nodes can be promoted to _supernodes_ based their available resources, such as computational power, uptime, and network throughput [@guha2005]. This can benefit real-time communication systems with high demands on bandwidth. For file-sharing systems, replicating archives and indexing data becomes highly relevant to ensure data availability and accessibility. Some of the systems discussed in @sec:related:p2p provide mirroring capabilities which retain original ownership and can guarantee for continuous data availability: Dat and IPFS have _pinning services_ [@benet2014], Secure Scuttlebutt has _pubs_ [@tarr2019], and Solid has _pods_ [@mansour2016].

Such services may again pose a risk for a P2P system by becoming too essential for the network's operation. Yet the underlying data structures and peer discovery mechanisms can ensure that data ownership and autonomy remains intact, even as inequality among peers increases and power shifts towards a small group of powerful peers---very much like a political system.

## Distributing Ownership {#sec:annotation:ownership}

Although treated equally by the architecture, peers can be vastly different in terms of their computational power and network resources. I have argued above for the need of supporting infrastructures in P2P systems to compensate for low-powered or ephemeral peers. Nodes that establish such infrastructures might be selective in which resources they propagate---e.g., relaying video calls to the university network or replicating an affiliated researcher's archives---, yet I assume that they provide these resources to the entire public community of peers. I call such nodes _public entities_, as they effectively serve the public and support maintaining the network's operation.

Such entities can complement the way how actual public institutions operate on the web. Digital libraries, for instance, provide collections of resources that are reasonably indexed and accessible via canonical identifiers. The Perseus Digital Library[^perseus-dl] and the British Library[^british-library] offer such collections. By providing them with rich annotation environments, high-availability replication, and archiving of their repositories, public entities on a P2P system can offer services for peers as they work on libraries' collections or create works of their own. 

<!-- ![Separation of annotations as personal data and resources as institutional data.](figures/ownership-separation.pdf){#fig:separation short-caption="Separation of personal and institutional ownership"} -->

Within this ecosystem of distributed networks and the web, with public services mediating in between, I introduce digital _notebooks_ as collections of personal annotations on a particular source. These notebooks should be considered private and thus their initial personal ownership should be conserved by cryptographic means. Furthermore, notebooks should be kept private even when sharing them with selected peers, either for display or active collaboration, and encryption should be leveraged to keep them private from third parties. They should be versioned explicitly to allow for time traveling, and should enforce an open data model for ensuring interoperability with a variety of applications and systems.

Fulfilling all of these requirements should render digital notebooks compatible with local-first software. In the following chapter \ref{sec:implementation}, I will detail two approaches on designing and implementing systems that incorporate the notions of notebooks and public entities in distributed systems while bridging distributed data into the web.

[^perseus-dl]: The aforementioned Perseus Digital Library provides a vast amount of classic texts and linguistic data online. The library’s Scaife Viewer allows for browsing its growing collection of texts available via CTS: <https://scaife.perseus.org/>.
[^british-library]: The British Library uses the IIIF standard for the offering of some of their digitized items: <https://www.bl.uk/subjects>.


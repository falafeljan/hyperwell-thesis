# Peer-to-Peer Annotation {#sec:annotation}

Despite its decentralized nature, resources on the web tend to be centralized on a small number of servers. This development increased even more amidst the rise of Big Data and the ongoing commodification of personal data, threatening data ownership and autonomy on the web. Arguably, academia and particularly Digital Humanities treat the web differently by embracing LD principles and establishing sustainable and self-organized infrastructures. Furthermore, with the Web Annotation specification issued by the W3C, academic annotation services can be provided by interoperable research environments and digital libraries alike. Considering annotation in the current situation, however, poses the following questions: Does annotation belong to the institutional domain? If it does not, how else to store and distribute them other than the web?

In the following, I will argue for the architectural separation between personal annotation and the respective sources based on the assumption that annotations are social data as opposed to public data. @Sec:annotation:web first revisits characteristics of the web. After questioning implications of cloud infrastructure in today's internet services, I will discuss the effects of decentralization in federated networks and P2P systems on digital annotation. P2P systems commonly rely on high-availability infrastructures known as _supernodes_ or _mirrors_ for replication and indexing. @Sec:annotation:infrastructure examines these infrastructures and draws inspiration from public services such as libraries.

In @sec:annotation:ownership, I then define the distinctive terms of _notebooks_ and _public entities_ for establishing a separation between personal data and public services in P2P networks and the web. Subsequently, in the following chapter \ref{sec:implementation} I discuss proof-of-concept designs and implementations on how such a separation can be realized with P2P technology.

## What's (Not) Wrong with Servers? {#sec:annotation:web}

The web establishes a decentralized network since hypertext systems commonly use a client-server model in order to distribute hypertext documents among a multitude of servers on the network [@berners-lee1989; @nelson1993]. This architectural decision brings its benefits and disadvantages. Smaller networks can benefit from this model by scaling easily and distributing resources predictably, yet large networks of world-wide scale can quickly outgrow their intention of being open, accessible, and collaborative, threatening their heterogeneity:

> _While the Web has the potential to enable full open access to knowledge, the code that powers the Web is not built for that. Instead, the Web uses a centralized data model optimized for use by commercial organizations. In other words, today’s Web values the access and voices of people who are valuable to corporate interests._ [@robinson2018, p. 2]

Businesses became increasingly occupied with harvesting personal data, which provides them with a highly-criticized[^cambridge-analytica][^shadow-profiles] substance for training targeted advertising models and personalization in news feeds [@bucher2012; @robinson2018]. The commodification of personal data by businesses consequently spoon-fed the progression of Big Data and the partitioning of the web into monolithic data silos [@srnicek2017]. Considering the resulting redistribution of resources on the web in its entirety, this inequality led to a fundamental break with the web's decentralized nature:

> _While the Web was originally conceived as a decentralised platform where every organisation and individual can participate, it became increasingly centralised with less than 1% of the servers serving more than 99% of the content._ [@capadisli2017, p. 469]

Arguably, LDP-supporting environments such as Solid and Dokieli attempt to mitigate such developments by emphasizing interoperability via server-to-server communication and open standards for data exchange [@mansour2016; @capadisli2017]. Based on fundamental web technologies, decentralized protocols like ActivityPub showed that the web can serve for growing autonomous and sustainable communities. Furthermore, publicly shared and semantically enriched data repositories can contribute to the digital commons. In Digital Humanities research, such contributions could arise as digital commentary via Web Annotation and digital gazetteers [@simon2017].

In this context, a published collection of annotations on a resource could be considered a critical commentary and thus make for a work of its own [@marshall1997; @marshall1998]. Marginal notes often provide context for sophisticated discussion among readers, effectively rendering such annotations social data. Furthermore, as \citeauthor{marshall1998} notes in her \citeyear{marshall1998} analysis of annotations, there exists a significant difference between annotations that have been made for private purposes and those which were created with public discussion in mind. Similar to a private diary, private annotations are created for private use, and thus personal ownership as well as privacy should be protected.

With _local-first software_, \citeauthor{kleppmann2019} introduce a novel type of application based on established concepts with the aim of retaining personal ownership on data [@kleppmann2019]. Conflict-free Replicated Data Types (CRDTs) are particularly well-suited for use in local-first applications. CRDTs provide strategies for conflict-free merging of changes that emerge from a distributed system with no centralized authority. Under the theoretical assumption of Strong Eventual Consistency (SEC), the retrieval of each separately obtained log of changes will eventually result in the same state across all peers of a system. By furthermore urging for data interoperability and encryption, \citeauthor{kleppmann2019} make local-first applications a promising contender for addressing the web's ownership issues.

Interestingly, the ecosystem of the web is changing. Rooted in the hype for P2P networks from the early 2000s, several protocols for hypermedia data-sharing emerged. Dat[^dat-foundation] and IPFS,[^ipfs] both attempt to provide a foundation for redistributing resources on the web. Still, some of their prospects are not fundamentally new and could actually contribute towards transforming the web to earlier notions of hypertext systems, such as content-addressable storage on Xanadu [@voss2019]. Today's browsers increasingly adopt these maturing protocols with support for Dat and IPFS present in Beaker[^beaker] and Opera,[^opera-ipfs] respectively.

However, novel systems which build upon these protocols will need to ensure interoperability with the current state of the web. The web offers vast amounts of knowledge, such publicly accessible PDF documents or semantically-tagged LOD repositories from DH research. It furthermore provides an efficient way for public entities, such as academic institutions and digital libraries, to publish content under their authority. In the following, I attempt to discuss the role of such entities in P2P systems.

[^cambridge-analytica]: <https://www.theguardian.com/technology/2019/jul/12/facebook-fine-ftc-privacy-violations>.
[^shadow-profiles]: <https://www.vox.com/2018/4/20/17254312/facebook-shadow-profiles-data-collection-non-users-mark-zuckerberg>.
[^dat-foundation]: <https://dat.foundation/>.
[^ipfs]: <https://ipfs.io/>.
[^beaker]: <https://beakerbrowser.com/>.
[^opera-ipfs]: The Opera browser for Android recently introduced support for resolving IPFS URLs: <https://blog.ipfs.io/2020-03-30-ipfs-in-opera-for-android/>.

## Public Entities in Peer-to-Peer Systems {#sec:annotation:infrastructure}

_Supernodes, relays, pubs, pods, gateways, pinning, seeding, mirroring:_ Many popular decentralized networks leverage infrastructures that provide resources for sustaining the networks’ operation. Such services are required, since P2P systems operate differently from established architectures that use the client-server model. These differences can be explained by how resources are distributed among clients and servers on such networks, where servers hold a monopoly on the network's resources while clients request parts of data on demand [@schollmeier2002]. This situation poses several benefits for entities such as businesses and institutions, since they are able to govern the singular source of their services’ data by actually _owning_ it. Hence, entities can effectively control and guarantee for aspects like data availability and access control.

In P2P systems, this power is distributed among peers. The distinction of clients and servers becomes blurred as the centralization of governance is diminished. Clients become servers while servers become clients, which results in a swarm of equal peers that serve and request data at the same time [@schollmeier2002]. Challenges are posed to P2P systems as they are frequented by peoples' personal computers, resulting in commodity hardware or even handheld devices joining the network ephemerally. This threatens data availability on P2P systems, since data vanishes as devices go offline.

Nevertheless, solutions exist to mitigate volatility or low-performance hardware among peers. In order to establish a stable and reliable network communications, nodes can be promoted to _supernodes_ based on their available resources, such as computational power, uptime, and network throughput [@guha2005]. Such nodes can benefit real-time communication systems with high demands on bandwidth. For file-sharing systems, the replication of archives and the indexing of data becomes highly relevant to ensure data availability and accessibility [@kleppmann2019]. Some of the systems discussed in @sec:related:p2p provide mirroring capabilities which retain original ownership and can guarantee for continuous data availability: Dat and IPFS have _pinning services_ [@benet2014], Secure Scuttlebutt has _pubs_ [@tarr2019], and Solid has _pods_ [@mansour2016].

Such services may again pose a risk for P2P systems by becoming too critical for the network's operation. The underlying data structures and peer discovery mechanisms can nonetheless ensure that data ownership and autonomy remain intact, even as inequality among peers increases and power shifts towards a small group of powerful peers.

## Distributing Ownership {#sec:annotation:ownership}

Although treated equally on a P2P network, peers can vastly differ from reach other in terms of their computational power and network resources. I have argued above for the need of supporting infrastructures on P2P networks to compensate low-performing hardware and ephemeral peers. Nodes that establish such infrastructures might be selective in which resources they propagate---e.g., relaying video calls to the university network or replicating an affiliated researcher's archives---yet I assume that they provide these resources to the entire public community of peers. I call such nodes _public entities_, as they effectively serve the public and support sustaining the network's operation.

Such entities can complement the way actual public institutions operate on the web. Digital libraries, for instance, provide collections of resources that are reasonably indexed and accessible via canonical identifiers. The Perseus Digital Library[^perseus-dl] and the British Library[^british-library] offer such collections. By their visitors them with rich annotation environments, high-availability replication, and archiving of their repositories, public entities on a P2P system can offer services for peers as they work on libraries' collections or create works of their own. 

Within this ecosystem of distributed networks and the web and public services mediating between them, I introduce _digital notebooks_ as collections of personal annotations on a particular source. These notebooks should be considered private and thus their individual ownership should be protected by cryptographic means. Furthermore, notebooks should be kept private from third parties even when sharing them with selected peers---for either display or active collaboration---by leveraging encryption. They should be explicitly versioned to allow for time traveling, and they should furthermore impose an open data model for ensuring interoperability with a variety of applications and systems.

Fulfilling all of these requirements should render digital notebooks compatible with local-first software. In the following chapter \ref{sec:implementation}, I will detail two approaches on designing and implementing systems that incorporate the notions of notebooks and public entities in distributed systems while bridging distributed data into the web.

[^perseus-dl]: The aforementioned Perseus Digital Library provides a vast amount of classic texts and linguistic data online. The library’s Scaife Viewer allows to browse its growing collection of texts available via CTS: <https://scaife.perseus.org/>.
[^british-library]: The British Library uses the IIIF standard for the offering of some of their digitized items: <https://www.bl.uk/subjects>.

